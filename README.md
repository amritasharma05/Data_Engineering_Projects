#### A repository containing all the data engineering projects.

Following is the summary of the projects contained in the repository

1. Capstone Project - The purpose of this project is to understand the immigration trends using a data pipeline created
using Spark and Parquet file format
 
2. Data Lakes Project - The purpose of the project is to build an ETL pipeline that extracts their data from S3, 
processes them using Spark, and loads the data back into S3 as a set of dimensional tables.

3. Data Modelling with Postgress - The purpose of this project is to define a fact and dimension tables for a star 
schema and write an ETL pipeline that transfers data from files in two local directories into these tables in Postgres using Python and SQL. 

4. Data Pipeline with Airflow - The purpose of this project is to develop a data warehouse ETL pipelines using Apache 
Airflow.

5. Data warehouse - The purpose of this project is to build an ETL pipeline that extracts their data from S3, stages them
in Redshift, and transforms data into a set of dimensional tables to find insights about what songs their users are listening to.






